knitr::opts_chunk$set(echo = TRUE)
# Function using for loop
fibonacci_ratio_for <- function(n) {
# Initialize the first two Fibonacci numbers
fib <- c(1, 1)
# Calculate the remaining Fibonacci numbers up to n+1
for (i in 3:(n+1)) {
fib[i] <- fib[i-1] + fib[i-2]
}
# Calculate the ratios
ratios <- fib[2:(n+1)] / fib[1:n]
return(ratios)
}
# Function using while loop
fibonacci_ratio_while <- function(n) {
# Initialize the first two Fibonacci numbers
fib <- c(1, 1)
# Calculate the remaining Fibonacci numbers up to n+1
i <- 3
while (i <= n+1) {
fib[i] <- fib[i-1] + fib[i-2]
i <- i + 1
}
# Calculate the ratios
ratios <- fib[2:(n+1)] / fib[1:n]
return(ratios)
}
# Load the microbenchmark package
library(microbenchmark)
# Benchmark for n = 200
benchmark_200 <- microbenchmark(
for_loop = fibonacci_ratio_for(200),
while_loop = fibonacci_ratio_while(200),
times = 100
)
print(benchmark_200)
# Benchmark for n = 2000
benchmark_2000 <- microbenchmark(
for_loop = fibonacci_ratio_for(2000),
while_loop = fibonacci_ratio_while(2000),
times = 100
)
print(benchmark_2000)
library(ggplot2)
# Plot for n = 200
autoplot(benchmark_200) +
ggtitle("Performance comparison for n = 200")
# Plot for n = 2000
autoplot(benchmark_2000) +
ggtitle("Performance comparison for n = 2000")
# Calculate the sequence for n = 100
ratios_100 <- fibonacci_ratio_for(100)
# Plot the sequence
plot(1:100, ratios_100, type = "l",
xlab = "i", ylab = "r_i = F_{i+1}/F_i",
main = "Ratio of consecutive Fibonacci numbers")
# Add a horizontal line at the golden ratio
abline(h = (1 + sqrt(5))/2, col = "red", lty = 2)
legend("bottomright", legend = c("Ratio sequence", "Golden ratio"),
col = c("black", "red"), lty = c(1, 2))
# Calculate the differences between consecutive ratios
diffs <- diff(ratios_100)
plot(1:99, abs(diffs), type = "l", log = "y",
xlab = "i", ylab = "Absolute difference between consecutive ratios",
main = "Convergence of the Fibonacci ratio")
# Print the first 20 ratios
data.frame(
i = 1:20,
ratio = ratios_100[1:20],
difference_from_golden_ratio = abs(ratios_100[1:20] - (1 + sqrt(5))/2)
)
# Calculate the golden ratio
golden_ratio <- (1 + sqrt(5))/2
print(paste("Golden ratio:", golden_ratio))
# Calculate when the sequence is within 1e-10 of the golden ratio
convergence_index <- min(which(abs(ratios_100 - golden_ratio) < 1e-10))
print(paste("The sequence converges to within 1e-10 of the golden ratio at i =", convergence_index))
# Set seed for reproducibility
set.seed(42)
# Number of rolls
n <- 10000
# Simulate rolling a fair die n times using vectorized function
rolls <- sample(1:6, n, replace = TRUE)
# Compute cumulative mean after each roll
cumulative_means <- cumsum(rolls) / (1:n)
# Plot the running average against the number of rolls
plot(1:n, cumulative_means, type = "l",
xlab = "Number of rolls", ylab = "Running average",
main = "Running Average of Die Rolls",
ylim = c(1, 6))
# Add a horizontal line at the expected value
abline(h = 3.5, col = "red", lty = 2)
legend("topright", legend = c("Running average", "Expected value (3.5)"),
col = c("black", "red"), lty = c(1, 2))
# Set seed for reproducibility
set.seed(123)
# Number of replications
M <- 50
# Matrix to store running averages for each replication
running_averages <- matrix(NA, nrow = M, ncol = n)
# For loop to replicate the experiment M times
for (i in 1:M) {
# Simulate rolling a die n times
rolls <- sample(1:6, n, replace = TRUE)
# Compute cumulative mean after each roll
running_averages[i, ] <- cumsum(rolls) / (1:n)
}
# Plot all 50 paths
plot(1:n, running_averages[1, ], type = "l",
xlab = "Number of rolls", ylab = "Running average",
main = "Running Average of Die Rolls (50 replications)",
ylim = c(2.5, 4.5), col = 1)
# Add the remaining 49 paths
for (i in 2:M) {
lines(1:n, running_averages[i, ], col = i)
}
# Add a horizontal line at the expected value
abline(h = 3.5, col = "red", lwd = 2)
legend("topright", legend = c("Replications", "Expected value (3.5)"),
col = c("black", "red"), lty = c(1, 1))
# Calculate absolute differences from expected value
abs_diff <- abs(running_averages - 3.5)
# Calculate mean absolute difference for each n
mean_abs_diff <- colMeans(abs_diff)
# Plot mean absolute difference
plot(1:n, mean_abs_diff, type = "l",
xlab = "Number of rolls", ylab = "Mean absolute difference from expected value",
main = "Convergence to Expected Value")
# Set seed for reproducibility
set.seed(456)
# Epsilon value
epsilon <- 0.01
# Initialize variables
n_current <- 0
proportion_outside <- 1
# Matrix to store running averages
running_averages <- matrix(NA, nrow = M, ncol = 1)
while (proportion_outside >= 0.05) {
# Increment n
n_current <- n_current + 100
# Resize the matrix if needed
if (ncol(running_averages) < n_current) {
running_averages <- cbind(running_averages, matrix(NA, nrow = M, ncol = 100))
}
# Update running averages for all replications
for (i in 1:M) {
# Generate new rolls
new_rolls <- sample(1:6, 100, replace = TRUE)
# If this is the first iteration, initialize
if (n_current == 100) {
running_averages[i, 1:100] <- cumsum(new_rolls) / (1:100)
} else {
# Calculate the sum up to n_current - 100
prev_sum <- running_averages[i, n_current - 100] * (n_current - 100)
# Add new rolls and calculate new running averages
new_sums <- prev_sum + cumsum(new_rolls)
running_averages[i, (n_current - 99):n_current] <- new_sums / ((n_current - 99):n_current)
}
}
# Check how many replications are outside the epsilon interval at n_current
outside_epsilon <- sum(abs(running_averages[, n_current] - 3.5) > epsilon)
proportion_outside <- outside_epsilon / M
# Print progress
cat("n =", n_current, "- Proportion outside epsilon:", proportion_outside, "\n")
}
# Final value of n
cat("The loop terminated at n =", n_current, "with proportion outside epsilon =", proportion_outside, "\n")
# Set seed for reproducibility
set.seed(789)
# Matrix to store running averages for Cauchy distribution
cauchy_averages <- matrix(NA, nrow = M, ncol = n)
# For loop to replicate the experiment M times
for (i in 1:M) {
# Simulate from standard Cauchy distribution
cauchy_samples <- rcauchy(n)
# Compute cumulative mean after each sample
cauchy_averages[i, ] <- cumsum(cauchy_samples) / (1:n)
}
# Plot all 50 paths
plot(1:n, cauchy_averages[1, ], type = "l",
xlab = "Number of samples", ylab = "Running average",
main = "Running Average of Cauchy Samples (50 replications)",
ylim = c(-10, 10), col = 1)
# Add the remaining 49 paths
for (i in 2:M) {
lines(1:n, cauchy_averages[i, ], col = i)
}
# Zoom in to see more detail
plot(1:n, cauchy_averages[1, ], type = "l",
xlab = "Number of samples", ylab = "Running average",
main = "Running Average of Cauchy Samples (Zoomed)",
ylim = c(-3, 3), col = 1)
for (i in 2:M) {
lines(1:n, cauchy_averages[i, ], col = i)
}
x_transformation <- function(){
#seed for reproducibility
set.seed(1)
#initialize x and z from normal distribution (100 values)
x <- rnorm(100)
z <- rnorm(100)
#4 iterations of transformation
for(i in 1:4){
#prevent diminishing values of x
threshold <- i * 0.001
if(sum(x >= threshold) < i) stop(paste("Step", i, "requires", i, "obs >= ", thr))
#fit linear model of x on z
fit <- lm(x ~ z)
#update x with sin(residuals), scale and add offset
x <- i * sin(fit$residuals) + 0.01 * i
}
#return transformed x
return(x)
}
x_transformation()
lm_cv_4fold <- function(){
# seed for reproducibility
set.seed(1)
#initialize x and y from normal distribution (1000 values)
x <- rnorm(1000)
y <- 2 + x + rnorm(1000)
df <- data.frame(x, y)
r <- c()
for(i in 1:4){
#fit linear model of y on x on i-th quarter
test <- ((i-1)*250+1):(i*250) # this is the 11-th line but it makes the code much more readable!
fit <- lm(y ~ x, data = df[-test,])
#predict y at test_indices
p <- predict(fit, newdata = df[test,])
#calculate RMSE and append
r <- c(r, sqrt(mean((df$y[test] - p)^2)))
}
return(r)
}
lm_cv_4fold()
kwtest <- function (x, g, ...)
{
if (is.list(x)) {
if (length(x) < 2L)
stop("'x' must be a list with at least 2 elements")
if (!missing(g))
warning("'x' is a list, so ignoring argument 'g'")
if (!all(sapply(x, is.numeric)))
warning("some elements of 'x' are not numeric and will be coerced to numeric")
k <- length(x)
l <- lengths(x)
if (any(l == 0L))
stop("all groups must contain data")
g <- factor(rep.int(seq_len(k), l))
x <- unlist(x)
}
else {
if (length(x) != length(g))
stop("'x' and 'g' must have the same length")
g <- factor(g)
k <- nlevels(g)
if (k < 2L)
stop("all observations are in the same group")
}
n <- length(x)
if (n < 2L)
stop("not enough observations")
r <- rank(x)
TIES <- table(x)
STATISTIC <- sum(tapply(r, g, sum)^2/tapply(r, g, length))
STATISTIC <- ((12 * STATISTIC/(n * (n + 1)) - 3 * (n + 1))/(1 -
sum(TIES^3 - TIES)/(n^3 - n)))
PARAMETER <- k - 1L
PVAL <- pchisq(STATISTIC, PARAMETER, lower.tail = FALSE)
names(STATISTIC) <- "Kruskal-Wallis chi-squared"
names(PARAMETER) <- "df"
RVAL <- list(statistic = STATISTIC, parameter = PARAMETER,
p.value = PVAL, method = "Kruskal-Wallis rank sum test")
return(RVAL)
}
group1 <- c(5.1, 5.5, 5.3)
group2 <- c(6.2, 6.4, 6.1)
group3 <- c(5.9, 6.0, 6.1)
result_list <- kwtest(list(group1, group2, group3))
result_list
x=list(group1, group2, group3)
if (is.list(x)) {
if (length(x) < 2L)
stop("'x' must be a list with at least 2 elements")
if (!missing(g))
warning("'x' is a list, so ignoring argument 'g'")
if (!all(sapply(x, is.numeric)))
warning("some elements of 'x' are not numeric and will be coerced to numeric")
k <- length(x)
l <- lengths(x)
if (any(l == 0L))
stop("all groups must contain data")
g <- factor(rep.int(seq_len(k), l))
x <- unlist(x)
}
g=NULL
if (length(x) < 2L)
stop("'x' must be a list with at least 2 elements")
if (!missing(g))
if (!all(sapply(x, is.numeric)))
k <- length(x)
l <- lengths(x)
if (any(l == 0L))
g <- factor(rep.int(seq_len(k), l))
x <- unlist(x)
n <- length(x)
if (n < 2L)
r <- rank(x)
TIES <- table(x)
r
r <- rank(x)
r
x
g
k <- length(x)
l <- lengths(x)
if (any(l == 0L))
stop("all groups must contain data")
g <- factor(rep.int(seq_len(k), l))
x=list(group1, group2, group3)
g=NULL
if (is.list(x)) {
if (length(x) < 2L)
stop("'x' must be a list with at least 2 elements")
if (!missing(g))
warning("'x' is a list, so ignoring argument 'g'")
if (!all(sapply(x, is.numeric)))
warning("some elements of 'x' are not numeric and will be coerced to numeric")
k <- length(x)
l <- lengths(x)
if (any(l == 0L))
stop("all groups must contain data")
g <- factor(rep.int(seq_len(k), l))
x <- unlist(x)
g
g
g
x=list(group1, group2, group3)
g=list()
if (is.list(x)) {
if (length(x) < 2L)
stop("'x' must be a list with at least 2 elements")
if (!missing(g))
warning("'x' is a list, so ignoring argument 'g'")
if (!all(sapply(x, is.numeric)))
warning("some elements of 'x' are not numeric and will be coerced to numeric")
k <- length(x)
l <- lengths(x)
if (any(l == 0L))
stop("all groups must contain data")
g <- factor(rep.int(seq_len(k), l))
x <- unlist(x)
g
r
g
r
n <- length(x)
if (n < 2L)
stop("not enough observations")
r <- rank(x)
TIES <- table(x)
n <- length(x)
if (n < 2L)
stop("not enough observations")
r <- rank(x)
TIES <- table(x)
STATISTIC <- sum(tapply(r, g, sum)^2/tapply(r, g, length))
STATISTIC <- ((12 * STATISTIC/(n * (n + 1)) - 3 * (n + 1))/(1 -
sum(TIES^3 - TIES)/(n^3 - n)))
g
r
g
r
